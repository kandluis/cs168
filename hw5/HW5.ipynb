{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 168 Spring Assignment 5\n",
    "\n",
    "SUNet ID(s): 05794739\n",
    "\n",
    "Name(s): Luis A. Perez\n",
    "\n",
    "Collaborators: None\n",
    "\n",
    "By turning in this assignment, I agree by the Stanford honor code and declare\n",
    "that all of this is my own work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn import decomposition\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from typing import Dict, List, Text, Tuple\n",
    "\n",
    "# Make figure larger\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "\n",
    "# Set numpy seed for consistent results.\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Globals:\n",
    "    DATA_PATH = 'data/'\n",
    "    \n",
    "def load_data(normalize=True, sparse=True):\n",
    "    \"\"\"Loads M (co-occurrence symmetric matrix) and and mapping from row/column idx to word.\"\"\"\n",
    "    with open(os.path.join(Globals.DATA_PATH, \"co_occur.csv\")) as f:\n",
    "        lines = f.readlines()\n",
    "    M = np.array([[float(count) for count in line.split(\",\")] for line in lines ])\n",
    "    with open(os.path.join(Globals.DATA_PATH, \"dictionary.txt\")) as f:\n",
    "        words = f.readlines()\n",
    "    idx_to_words = dict(enumerate([word.strip() for word in words]))\n",
    "    normM = np.log(1 + M) if normalize else M\n",
    "    return scipy.sparse.csr_matrix(normM), idx_to_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "M, idx_to_words = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, VT = scipy.sparse.linalg.svds(M, k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def problem1b(M, S):\n",
    "    plt.title(\"Singular Values in Order From Largest to Smallest\")\n",
    "    plt.xlabel(\"n-th singular value from largest to smallest\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.plot(range(len(S)), sorted(S, reverse=True))\n",
    "    plt.savefig(\"figures/singular_values.png\", format='png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem1b(M, S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1c\n",
    "\n",
    "Repeat with different values if $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_and_least_frequent_words(i):\n",
    "    \"\"\"Returns list of 10 most/least frequent words in eigenvector v_i.\"\"\"\n",
    "    vi = U[:, U.shape[1] - i]\n",
    "    sorted_idx = np.argsort(vi)\n",
    "    bottom_10 = [idx_to_words[i] for i in sorted_idx[:10]]\n",
    "    top_10 = [idx_to_words[i] for i in sorted_idx[-10:]]\n",
    "    print(\"Top 10 Words\")\n",
    "    print(top_10)\n",
    "    print(\"Bottom 10 Words\")\n",
    "    print(bottom_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Words\n",
      "['michael', 'thomas', 'george', 'jr', 'william', 'robert', 'david', 'james', 'john', 'born']\n",
      "Bottom 10 Words\n",
      "['specific', 'any', 'data', 'provide', 'these', 'certain', 'different', 'systems', 'its', 'use']\n"
     ]
    }
   ],
   "source": [
    "get_most_and_least_frequent_words(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "correction = np.zeros(x.shape)\n",
    "correction[3985] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Words\n",
      "['electronic', 'web', 'online', 'research', 'computer', 'engineering', 'technology', 'software', 'science', 'digital']\n",
      "Bottom 10 Words\n",
      "['troops', 'him', 'killed', 'soldiers', 'they', 'them', 'were', 'had', 'emperor', 'attacked']\n"
     ]
    }
   ],
   "source": [
    "get_most_and_least_frequent_words(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Words\n",
      "['entered', 'became', 'came', 'moved', 'served', 'joined', 'led', 'brought', 'gave', 'took']\n",
      "Bottom 10 Words\n",
      "['him', 'them', 'it', 'himself', 'her', 'students', 'who', 'government', 'people', 'players']\n"
     ]
    }
   ],
   "source": [
    "get_most_and_least_frequent_words(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Words\n",
      "['subsequent', 'scenes', 'combat', 'completed', 'training', 'artillery', 'battle', 'brief', 'naval', 'squadron']\n",
      "Bottom 10 Words\n",
      "['brazil', 'products', 'food', 'income', 'municipality', 'born', 'population', 'name', 'milk', 'province']\n"
     ]
    }
   ],
   "source": [
    "get_most_and_least_frequent_words(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Words\n",
      "['institute', 'band', 'records', 'remix', 'and', 'university', 'vol', 'cd', 'album', 'lp']\n",
      "Bottom 10 Words\n",
      "['characters', 'television', 'location', 'character', 'actor', 'channel', 'bbc', 'plot', 'journalist', 'actress']\n"
     ]
    }
   ],
   "source": [
    "get_most_and_least_frequent_words(22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def problem1d(U):\n",
    "    word_to_idx = {word : idx for idx, word in idx_to_words.items() }\n",
    "    normU = U / np.linalg.norm(U, axis=1, keepdims=True)\n",
    "    v1 = normU[word_to_idx[\"woman\"], :]\n",
    "    v2 = normU[word_to_idx[\"man\"], :]\n",
    "    v = v1 - v2\n",
    "    \n",
    "    def project(to_project, title):\n",
    "        # See https://stackoverflow.com/questions/23186804/graph-point-on-straight-line-number-line-in-python\n",
    "        xmin = -0.5\n",
    "        xmax = 0.5\n",
    "        y = 0\n",
    "        height = 1\n",
    "\n",
    "        plt.hlines(y, xmin, xmax)\n",
    "\n",
    "        for i, word in enumerate(to_project):\n",
    "            x = np.dot(v, normU[word_to_idx[word]])\n",
    "\n",
    "            plt.plot(x, y, 'bo')\n",
    "\n",
    "            plt.annotate(word, (x,y), xytext = (x, y + np.random.uniform(low=-0.05, high=0.05)), \n",
    "                         arrowprops={'arrowstyle': '->'})\n",
    "        \n",
    "        plt.title(\"Projection of Differnt Words\")\n",
    "        plt.xlabel(\"Similarity\")\n",
    "        plt.savefig(f'figures/{title}.png', format=\"png\")\n",
    "        plt.close()\n",
    "\n",
    "    project(['math', 'matrix', 'history', 'nurse', 'doctor', 'pilot',\n",
    "             'teacher', 'engineer', 'science', 'arts', 'literature',\n",
    "             'bob', 'alice'],\n",
    "           title='projection_ton_femaleness_2')\n",
    "    project(['boy', 'girl', 'brother', 'sister', 'king', 'queen',\n",
    "                  'he', 'she', 'john', 'mary', 'wall', 'tree'],\n",
    "            title='projection_onto_femaleness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem1d(U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_word(query, idx_to_ignore=None):\n",
    "    query_idx = None\n",
    "    word_to_idx = {word : idx for idx, word in idx_to_words.items() }\n",
    "    if type(query) == str:\n",
    "        query_idx = word_to_idx[query]\n",
    "        query = U[word_to_idx[query], :]\n",
    "    sims = np.dot(U, query.T)\n",
    "    correction = np.zeros(sims.shape)\n",
    "    if idx_to_ignore:\n",
    "        for idx in idx_to_ignore:\n",
    "            correction[idx] = 1\n",
    "    if query_idx:\n",
    "        correction[query_idx] = 1\n",
    "    idx = np.argmax(sims - 10 * np.max(sims) * correction)\n",
    "    return idx_to_words[idx]\n",
    "    \n",
    "def load_analogy_examples():\n",
    "    with open(os.path.join(Globals.DATA_PATH, 'analogy_task.txt')) as f:\n",
    "        tasks = f.readlines()\n",
    "    return [tuple(word.strip() for word in task.split(' ')) for task in tasks]\n",
    "\n",
    "def accuracy_on_analogy_task(tasks):\n",
    "    # Task is 'a' is to 'b' as 'c' is to 'd'\n",
    "    word_to_idx = {word : idx for idx, word in idx_to_words.items() }\n",
    "    def _v(x):\n",
    "        return U[word_to_idx[x], :]\n",
    "    wrong = []\n",
    "    for (a, b, c, d) in tasks:\n",
    "        v1, v2, v3 = _v(a), _v(b), _v(c)\n",
    "        guess = closest_word(v2 - v1 + v3, idx_to_ignore=[\n",
    "            word_to_idx[a],\n",
    "            word_to_idx[b],\n",
    "            word_to_idx[c]\n",
    "        ])\n",
    "        if guess != d:\n",
    "            wrong.append((a, b, c, d, guess))\n",
    "    return 1 - len(wrong) / len(tasks), wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def problem1e():\n",
    "    # Part 1.\n",
    "    print(f\"The closest word to 'stanford' is '{closest_word('stanford')}'.\")\n",
    "    \n",
    "    # Part 2.\n",
    "    acc, wrong = accuracy_on_analogy_task(load_analogy_examples())\n",
    "    print(f\"The accuracy on the analogy task is {100*acc}%.\")\n",
    "    return wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The closest word to 'stanford' is 'harvard'.\n",
      "The accuracy on the analogy task is 31.15487914055506%.\n"
     ]
    }
   ],
   "source": [
    "wrong_analogies = problem1e()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_low_rank(image_array, ks):\n",
    "    max_k = max(ks)\n",
    "    U, D, VT = scipy.sparse.linalg.svds(image_array, k=max_k)\n",
    "    D = np.diag(D)\n",
    "    approx = {}\n",
    "    for k in ks:\n",
    "        approx[k] = np.dot(np.dot(U[:, :k], D[:k, :k]), VT[:k, :])\n",
    "    return approx\n",
    "\n",
    "def load_image():\n",
    "    alice = Image.open(os.path.join(Globals.DATA_PATH, 'p5_image.gif'))\n",
    "    bits = scipy.sparse.csr_matrix(np.asarray(alice).astype(np.float32))\n",
    "    return bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(bits):\n",
    "    bits = bits - np.min(bits)\n",
    "    bits = bits / np.max(bits)\n",
    "    data = (bits * 255).astype(np.uint8)\n",
    "    image = Image.fromarray(data)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def problem2bd():\n",
    "    img = load_image()\n",
    "    ks = [1,3,10,20,50,100,150 ,200,400, 800, 1700]\n",
    "    recovered = recover_low_rank(img, ks)\n",
    "    compressed = get_image(recovered[150])\n",
    "    compressed.save(\"figures/low_rank_alice.png\", format='PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem2bd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs168",
   "language": "python",
   "name": "cs168"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
