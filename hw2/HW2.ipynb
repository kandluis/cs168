{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 168 Spring Assignment 2\n",
    "\n",
    "SUNet ID(s): 05794739\n",
    "\n",
    "Name(s): Luis A. Perez\n",
    "\n",
    "Collaborators: None\n",
    "\n",
    "By turning in this assignment, I agree by the Stanford honor code and declare\n",
    "that all of this is my own work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from typing import Dict, List, Text, Tuple\n",
    "\n",
    "# Make figure larger\n",
    "plt.rcParams['figure.figsize'] = [10, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Globals:\n",
    "    \"\"\"Class holding globals to avoid polluting workspace.\"\"\"\n",
    "    DATA_DIR: Text = 'p2_data'\n",
    "    LABEL: Text = 'label.csv'\n",
    "    GROUPS: Text = 'groups.csv'\n",
    "    DATA: Text = 'data50.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeHeatMap(data, names, color, outputFileName):\n",
    "    \"\"\"Makes a 20x20 heatmap from the given 20x20 data matrix.\"\"\"\n",
    "    # to catch \"falling back to Agg\" warning\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        # code source: http://stackoverflow.com/questions/14391959/heatmap-in-matplotlib-with-pcolor\n",
    "        fig, ax = plt.subplots()\n",
    "        # create the map w/ color bar legend\n",
    "        heatmap = ax.pcolor(data, cmap=color)\n",
    "        cbar = plt.colorbar(heatmap)\n",
    "\n",
    "        # put the major ticks at the middle of each cell\n",
    "        ax.set_xticks(np.arange(data.shape[0]) + 0.5, minor=False)\n",
    "        ax.set_yticks(np.arange(data.shape[1]) + 0.5, minor=False)\n",
    "\n",
    "        # want a more natural, table-like display\n",
    "        ax.invert_yaxis()\n",
    "        ax.xaxis.tick_top()\n",
    "\n",
    "        ax.set_xticklabels(range(1, 21))\n",
    "        ax.set_yticklabels(names)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.savefig(outputFileName, format='png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bag_of_words(data: pd.DataFrame) -> collections.Counter:\n",
    "    \"\"\"Transforms a pandas dataframe into a bag of words counter.\n",
    "    \n",
    "    Args:\n",
    "        data, with columns 'wordId' and 'count'\n",
    "        \n",
    "    Returns:\n",
    "        The bag of words (mapping from wordId to count).\n",
    "    \"\"\"\n",
    "    return collections.Counter({\n",
    "        wordId: count for wordId, count in zip(data.wordId, data['count'])})\n",
    "        \n",
    "def read_data() -> Tuple[Dict[int, int], Dict[int, List[int]], pd.DataFrame]:\n",
    "    \"\"\"Reads the relevant data files.\n",
    "    \n",
    "    Returns:\n",
    "        A tuple of items. The bag of words object and for each \n",
    "        article (keyed by articleId) and a mapping from\n",
    "        groupId to a list of corresponding articleIds in that group.\n",
    "        Also the entire dataset as a pd.DataFrame.\n",
    "    \"\"\"\n",
    "    # Maps to groupId.\n",
    "    labels = pd.read_csv(\n",
    "        os.path.join(Globals.DATA_DIR, Globals.LABEL), header=None,\n",
    "        names=['groupId'])\n",
    "    labels['articleId'] = range(1, len(labels) + 1)\n",
    "    # Maps to groupName.\n",
    "    groups = pd.read_csv(\n",
    "        os.path.join(Globals.DATA_DIR,\n",
    "                     Globals.GROUPS), header=None,\n",
    "        names=['name'])\n",
    "    groups['groupId'] = range(1, len(groups) + 1)\n",
    "    data = pd.read_csv(\n",
    "        os.path.join(Globals.DATA_DIR, Globals.DATA), header=None,\n",
    "        names=['articleId', 'wordId', 'count'])\n",
    "    data = data.merge(labels, on='articleId').merge(groups, on='groupId')\n",
    "    # Transform into a dictionary mapping articleId to a collections.Counter\n",
    "    # object counting each word (based on wordId).\n",
    "    group_to_name = {groupId : data[data.groupId == groupId].name.iloc[0]\n",
    "                    for groupId in data.groupId.unique()}\n",
    "    article_to_bow = {articleId : get_bag_of_words(data[data.articleId == articleId])\n",
    "            for articleId in data.articleId.unique()}\n",
    "    group_to_article = { groupId : data[data.groupId == groupId].articleId.unique()\n",
    "                       for groupId in data.groupId.unique()}\n",
    "    return article_to_bow, group_to_article, group_to_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_sim(x: Dict[int, int], y: Dict[int, int]) -> float:\n",
    "    \"\"\"Given two bag-of-word representations, calculate their Jaccard Similarity.\"\"\"\n",
    "    num = 0\n",
    "    den = 0\n",
    "    for wordId in (set(x.keys()) | set(y.keys())):\n",
    "        num += min(x[wordId], y[wordId])\n",
    "        den += max(x[wordId], y[wordId])\n",
    "    return num / den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lp_sim(x: Dict[int, int], y: Dict[int, int], p: int = 2) -> float:\n",
    "    \"\"\"Given two bag-of-word representations, calculate their l_p norm similarity.\"\"\"\n",
    "    squaredSum = 0\n",
    "    for wordId in (set(x.keys()) | set(y.keys())):\n",
    "        squaredSum += (x[wordId] - y[wordId])**p\n",
    "    return -np.sqrt(squaredSum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(x: Dict[int, int], y: Dict[int, int]) -> float:\n",
    "    \"\"\"Given two bag-of-word representations, calculate their cosine similarity.\"\"\"\n",
    "    xNorm = np.linalg.norm(list(x.values()))\n",
    "    yNorm = np.linalg.norm(list(y.values()))\n",
    "    dotProduct = 0\n",
    "    for wordId in (set(x.keys()) | set(y.keys())):\n",
    "        dotProduct += (x[wordId] * y[wordId])\n",
    "    return dotProduct / (xNorm * yNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_similarity(articles, groups_to_articles, sim_fn, groupA: int, groupB: int) -> float:\n",
    "    \"\"\"Computes the average similarity between the two specified groups.\"\"\"\n",
    "    articlesA = groups_to_articles[groupA]\n",
    "    articlesB = groups_to_articles[groupB]\n",
    "    # Even though all of our existing sim_fn are symmetric, do\n",
    "    # all pairs in-case this doesn't hold true in general.\n",
    "    scores = [sim_fn(articles[Aidx], articles[Bidx])\n",
    "              for Aidx in articlesA for Bidx in articlesB]\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_matrix(articles, groups_to_articles, sim_fn, max_groups=None):\n",
    "    \"\"\"Computes the similarity matrix using the given sim_fn for all groups.\"\"\"\n",
    "    groups = sorted(groups_to_articles.keys())\n",
    "    if not max_groups: max_groups = len(groups)\n",
    "    data = np.zeros((20,20))\n",
    "    for i, groupA in enumerate(groups[:max_groups]):\n",
    "        for j, groupB in enumerate(groups[:max_groups]):\n",
    "            data[i][j] = average_similarity(\n",
    "                articles, groups_to_articles, sim_fn, groupA, groupB)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_sim_matrices(articles, groups_to_articles, sim_fns):\n",
    "    \"\"\"Computes all similarity matrices for all given sim_fns.\"\"\"\n",
    "    data = {}\n",
    "    for name, sim_fn in sim_fns.items():\n",
    "        data[name] = get_similarity_matrix(articles, groups_to_articles, sim_fn)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmaps(input_data, sim_fns):\n",
    "    \"\"\"Plots and saves heatmaps for different similarity functions.\"\"\"\n",
    "    articles, groups_to_articles, group_names = input_data\n",
    "    names = [group_names[i] for i in sorted(group_names.keys())]\n",
    "    all_data = get_all_sim_matrices(articles, groups_to_articles, sim_fns)\n",
    "    for name, data in all_data.items():\n",
    "        makeHeatMap(data, names, color='Blues',\n",
    "                    outputFileName=\"figures/{name}.png\".format(name=name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def problem_2b():\n",
    "    \"\"\"Solves problem 2b from Mini-Project 2\"\"\"\n",
    "    input_data = read_data()\n",
    "    plot_heatmaps(input_data, {\n",
    "        'Cosine' : cosine_sim,\n",
    "        'Jaccard': jaccard_sim,\n",
    "        'L2' : lp_sim })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_2b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1585"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(article.keys()) for article in x[0].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs168",
   "language": "python",
   "name": "cs168"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
